{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_path = \"C:/Users/shabbir.hasan/Documents/Hasan/Anaconda_rep/Kaggle/whats-cooking/train.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_file_path, encoding='utf-8') as data_file:\n",
    "    data = json.loads(data_file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.io.json import json_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = json_normalize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cuisine</th>\n",
       "      <th>id</th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>greek</td>\n",
       "      <td>10259</td>\n",
       "      <td>[romaine lettuce, black olives, grape tomatoes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>southern_us</td>\n",
       "      <td>25693</td>\n",
       "      <td>[plain flour, ground pepper, salt, tomatoes, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>filipino</td>\n",
       "      <td>20130</td>\n",
       "      <td>[eggs, pepper, salt, mayonaise, cooking oil, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>indian</td>\n",
       "      <td>22213</td>\n",
       "      <td>[water, vegetable oil, wheat, salt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>indian</td>\n",
       "      <td>13162</td>\n",
       "      <td>[black pepper, shallots, cornflour, cayenne pe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cuisine     id                                        ingredients\n",
       "0        greek  10259  [romaine lettuce, black olives, grape tomatoes...\n",
       "1  southern_us  25693  [plain flour, ground pepper, salt, tomatoes, g...\n",
       "2     filipino  20130  [eggs, pepper, salt, mayonaise, cooking oil, g...\n",
       "3       indian  22213                [water, vegetable oil, wheat, salt]\n",
       "4       indian  13162  [black pepper, shallots, cornflour, cayenne pe..."
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_long_str(inp):\n",
    "    temp_str = ''\n",
    "    for i in inp:\n",
    "        temp_str += ' ' + (i.replace(\"''\", '')) \n",
    "    return temp_str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ingredients_str'] = df.ingredients.apply(create_long_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load nltk's SnowballStemmer as variabled 'stemmer'\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_stem(text):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(re.sub('<.*?>', ' ', token))\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ingredients_stem'] = df['ingredients_str'].apply(tokenize_and_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cuisine</th>\n",
       "      <th>id</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>ingredients_str</th>\n",
       "      <th>ingredients_stem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>greek</td>\n",
       "      <td>10259</td>\n",
       "      <td>[romaine lettuce, black olives, grape tomatoes...</td>\n",
       "      <td>romaine lettuce black olives grape tomatoes ga...</td>\n",
       "      <td>[romain, lettuc, black, oliv, grape, tomato, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>southern_us</td>\n",
       "      <td>25693</td>\n",
       "      <td>[plain flour, ground pepper, salt, tomatoes, g...</td>\n",
       "      <td>plain flour ground pepper salt tomatoes ground...</td>\n",
       "      <td>[plain, flour, ground, pepper, salt, tomato, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>filipino</td>\n",
       "      <td>20130</td>\n",
       "      <td>[eggs, pepper, salt, mayonaise, cooking oil, g...</td>\n",
       "      <td>eggs pepper salt mayonaise cooking oil green c...</td>\n",
       "      <td>[egg, pepper, salt, mayonais, cook, oil, green...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>indian</td>\n",
       "      <td>22213</td>\n",
       "      <td>[water, vegetable oil, wheat, salt]</td>\n",
       "      <td>water vegetable oil wheat salt</td>\n",
       "      <td>[water, veget, oil, wheat, salt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>indian</td>\n",
       "      <td>13162</td>\n",
       "      <td>[black pepper, shallots, cornflour, cayenne pe...</td>\n",
       "      <td>black pepper shallots cornflour cayenne pepper...</td>\n",
       "      <td>[black, pepper, shallot, cornflour, cayenn, pe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       cuisine     id                                        ingredients  \\\n",
       "0        greek  10259  [romaine lettuce, black olives, grape tomatoes...   \n",
       "1  southern_us  25693  [plain flour, ground pepper, salt, tomatoes, g...   \n",
       "2     filipino  20130  [eggs, pepper, salt, mayonaise, cooking oil, g...   \n",
       "3       indian  22213                [water, vegetable oil, wheat, salt]   \n",
       "4       indian  13162  [black pepper, shallots, cornflour, cayenne pe...   \n",
       "\n",
       "                                     ingredients_str  \\\n",
       "0  romaine lettuce black olives grape tomatoes ga...   \n",
       "1  plain flour ground pepper salt tomatoes ground...   \n",
       "2  eggs pepper salt mayonaise cooking oil green c...   \n",
       "3                     water vegetable oil wheat salt   \n",
       "4  black pepper shallots cornflour cayenne pepper...   \n",
       "\n",
       "                                    ingredients_stem  \n",
       "0  [romain, lettuc, black, oliv, grape, tomato, g...  \n",
       "1  [plain, flour, ground, pepper, salt, tomato, g...  \n",
       "2  [egg, pepper, salt, mayonais, cook, oil, green...  \n",
       "3                   [water, veget, oil, wheat, salt]  \n",
       "4  [black, pepper, shallot, cornflour, cayenn, pe...  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.drop(['ingredients', 'ingredients_str'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = Pipeline([\n",
    "     ('tfidf', TfidfVectorizer(max_df=0.95, min_df=3, \n",
    "                                  max_features=1000,\n",
    "#                                   tokenizer=tokenize_and_stem,\n",
    "                                  stop_words='english', ngram_range=(1, 3))),\n",
    "    ('svd', TruncatedSVD()),\n",
    "#     ('clf', OneVsRestClassifier(SGDClassifier(class_weight='balanced', \n",
    "#                                               alpha=1e-3, random_state=42,\n",
    "#                                               max_iter=5, tol=None)))\n",
    "    ('clf', RandomForestClassifier())\n",
    " \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "params = {\n",
    "    'tfidf__max_df': (0.8, 0.95), # 0.95),\n",
    "    'svd__n_components': (100,200),\n",
    "    'clf__n_estimators': (100,150),\n",
    "    'clf__max_depth': (5,10)\n",
    "#     'clf__estimator__alpha': (1e-2), #, 1e-3)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch = GridSearchCV(text_clf, params, scoring='accuracy', refit=True, cv=2, verbose=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 16 candidates, totalling 32 fits\n",
      "[CV] clf__max_depth=5, clf__n_estimators=100, svd__n_components=100, tfidf__max_df=0.8 \n",
      "[CV]  clf__max_depth=5, clf__n_estimators=100, svd__n_components=100, tfidf__max_df=0.8, score=0.4839893429849696, total=  11.4s\n",
      "[CV] clf__max_depth=5, clf__n_estimators=100, svd__n_components=100, tfidf__max_df=0.8 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   12.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__max_depth=5, clf__n_estimators=100, svd__n_components=100, tfidf__max_df=0.8, score=0.49137367335647103, total=  11.3s\n",
      "[CV] clf__max_depth=5, clf__n_estimators=100, svd__n_components=100, tfidf__max_df=0.95 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   25.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__max_depth=5, clf__n_estimators=100, svd__n_components=100, tfidf__max_df=0.95, score=0.47871110440858594, total=  11.2s\n",
      "[CV] clf__max_depth=5, clf__n_estimators=100, svd__n_components=100, tfidf__max_df=0.95 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   37.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__max_depth=5, clf__n_estimators=100, svd__n_components=100, tfidf__max_df=0.95, score=0.4965544992706604, total=  11.1s\n",
      "[CV] clf__max_depth=5, clf__n_estimators=100, svd__n_components=200, tfidf__max_df=0.8 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   50.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf__max_depth=5, clf__n_estimators=100, svd__n_components=200, tfidf__max_df=0.8, score=0.4585029910018599, total=  15.4s\n",
      "[CV] clf__max_depth=5, clf__n_estimators=100, svd__n_components=200, tfidf__max_df=0.8 \n",
      "[CV]  clf__max_depth=5, clf__n_estimators=100, svd__n_components=200, tfidf__max_df=0.8, score=0.4628036819073487, total=  15.3s\n",
      "[CV] clf__max_depth=5, clf__n_estimators=100, svd__n_components=200, tfidf__max_df=0.95 \n",
      "[CV]  clf__max_depth=5, clf__n_estimators=100, svd__n_components=200, tfidf__max_df=0.95, score=0.4567435781430654, total=  15.4s\n",
      "[CV] clf__max_depth=5, clf__n_estimators=100, svd__n_components=200, tfidf__max_df=0.95 \n",
      "[CV]  clf__max_depth=5, clf__n_estimators=100, svd__n_components=200, tfidf__max_df=0.95, score=0.46179769629294304, total=  15.3s\n",
      "[CV] clf__max_depth=5, clf__n_estimators=150, svd__n_components=100, tfidf__max_df=0.8 \n",
      "[CV]  clf__max_depth=5, clf__n_estimators=150, svd__n_components=100, tfidf__max_df=0.8, score=0.48283315739204746, total=  15.2s\n",
      "[CV] clf__max_depth=5, clf__n_estimators=150, svd__n_components=100, tfidf__max_df=0.8 \n",
      "[CV]  clf__max_depth=5, clf__n_estimators=150, svd__n_components=100, tfidf__max_df=0.8, score=0.49569941149841557, total=  15.2s\n",
      "[CV] clf__max_depth=5, clf__n_estimators=150, svd__n_components=100, tfidf__max_df=0.95 \n",
      "[CV]  clf__max_depth=5, clf__n_estimators=150, svd__n_components=100, tfidf__max_df=0.95, score=0.4808223998391394, total=  15.4s\n",
      "[CV] clf__max_depth=5, clf__n_estimators=150, svd__n_components=100, tfidf__max_df=0.95 \n",
      "[CV]  clf__max_depth=5, clf__n_estimators=150, svd__n_components=100, tfidf__max_df=0.95, score=0.4988179669030733, total=  15.2s\n",
      "[CV] clf__max_depth=5, clf__n_estimators=150, svd__n_components=200, tfidf__max_df=0.8 \n",
      "[CV]  clf__max_depth=5, clf__n_estimators=150, svd__n_components=200, tfidf__max_df=0.8, score=0.4630271954959031, total=  21.3s\n",
      "[CV] clf__max_depth=5, clf__n_estimators=150, svd__n_components=200, tfidf__max_df=0.8 \n",
      "[CV]  clf__max_depth=5, clf__n_estimators=150, svd__n_components=200, tfidf__max_df=0.8, score=0.4617473970122227, total=  20.9s\n",
      "[CV] clf__max_depth=5, clf__n_estimators=150, svd__n_components=200, tfidf__max_df=0.95 \n",
      "[CV]  clf__max_depth=5, clf__n_estimators=150, svd__n_components=200, tfidf__max_df=0.95, score=0.45820137736892375, total=  21.2s\n",
      "[CV] clf__max_depth=5, clf__n_estimators=150, svd__n_components=200, tfidf__max_df=0.95 \n",
      "[CV]  clf__max_depth=5, clf__n_estimators=150, svd__n_components=200, tfidf__max_df=0.95, score=0.47502640712237815, total=  21.4s\n",
      "[CV] clf__max_depth=10, clf__n_estimators=100, svd__n_components=100, tfidf__max_df=0.8 \n",
      "[CV]  clf__max_depth=10, clf__n_estimators=100, svd__n_components=100, tfidf__max_df=0.8, score=0.5706027245764842, total=  17.7s\n",
      "[CV] clf__max_depth=10, clf__n_estimators=100, svd__n_components=100, tfidf__max_df=0.8 \n",
      "[CV]  clf__max_depth=10, clf__n_estimators=100, svd__n_components=100, tfidf__max_df=0.8, score=0.5791962174940898, total=  17.3s\n",
      "[CV] clf__max_depth=10, clf__n_estimators=100, svd__n_components=100, tfidf__max_df=0.95 \n",
      "[CV]  clf__max_depth=10, clf__n_estimators=100, svd__n_components=100, tfidf__max_df=0.95, score=0.571306489720002, total=  17.4s\n",
      "[CV] clf__max_depth=10, clf__n_estimators=100, svd__n_components=100, tfidf__max_df=0.95 \n",
      "[CV]  clf__max_depth=10, clf__n_estimators=100, svd__n_components=100, tfidf__max_df=0.95, score=0.579045319651929, total=  17.4s\n",
      "[CV] clf__max_depth=10, clf__n_estimators=100, svd__n_components=200, tfidf__max_df=0.8 \n",
      "[CV]  clf__max_depth=10, clf__n_estimators=100, svd__n_components=200, tfidf__max_df=0.8, score=0.5600965163625395, total=  24.2s\n",
      "[CV] clf__max_depth=10, clf__n_estimators=100, svd__n_components=200, tfidf__max_df=0.8 \n",
      "[CV]  clf__max_depth=10, clf__n_estimators=100, svd__n_components=200, tfidf__max_df=0.8, score=0.5722549167546904, total=  23.9s\n",
      "[CV] clf__max_depth=10, clf__n_estimators=100, svd__n_components=200, tfidf__max_df=0.95 \n",
      "[CV]  clf__max_depth=10, clf__n_estimators=100, svd__n_components=200, tfidf__max_df=0.95, score=0.5642688382848238, total=  24.2s\n",
      "[CV] clf__max_depth=10, clf__n_estimators=100, svd__n_components=200, tfidf__max_df=0.95 \n",
      "[CV]  clf__max_depth=10, clf__n_estimators=100, svd__n_components=200, tfidf__max_df=0.95, score=0.5699411498415573, total=  24.4s\n",
      "[CV] clf__max_depth=10, clf__n_estimators=150, svd__n_components=100, tfidf__max_df=0.8 \n",
      "[CV]  clf__max_depth=10, clf__n_estimators=150, svd__n_components=100, tfidf__max_df=0.8, score=0.5734680540893782, total=  24.4s\n",
      "[CV] clf__max_depth=10, clf__n_estimators=150, svd__n_components=100, tfidf__max_df=0.8 \n",
      "[CV]  clf__max_depth=10, clf__n_estimators=150, svd__n_components=100, tfidf__max_df=0.8, score=0.5828680649866707, total=  24.4s\n",
      "[CV] clf__max_depth=10, clf__n_estimators=150, svd__n_components=100, tfidf__max_df=0.95 \n",
      "[CV]  clf__max_depth=10, clf__n_estimators=150, svd__n_components=100, tfidf__max_df=0.95, score=0.5731161715176193, total=  24.6s\n",
      "[CV] clf__max_depth=10, clf__n_estimators=150, svd__n_components=100, tfidf__max_df=0.95 \n",
      "[CV]  clf__max_depth=10, clf__n_estimators=150, svd__n_components=100, tfidf__max_df=0.95, score=0.5820129772144258, total=  24.6s\n",
      "[CV] clf__max_depth=10, clf__n_estimators=150, svd__n_components=200, tfidf__max_df=0.8 \n",
      "[CV]  clf__max_depth=10, clf__n_estimators=150, svd__n_components=200, tfidf__max_df=0.8, score=0.5602975921178304, total=  34.6s\n",
      "[CV] clf__max_depth=10, clf__n_estimators=150, svd__n_components=200, tfidf__max_df=0.8 \n",
      "[CV]  clf__max_depth=10, clf__n_estimators=150, svd__n_components=200, tfidf__max_df=0.8, score=0.5717016246667672, total=  34.3s\n",
      "[CV] clf__max_depth=10, clf__n_estimators=150, svd__n_components=200, tfidf__max_df=0.95 \n",
      "[CV]  clf__max_depth=10, clf__n_estimators=150, svd__n_components=200, tfidf__max_df=0.95, score=0.5661790579600865, total=  34.3s\n",
      "[CV] clf__max_depth=10, clf__n_estimators=150, svd__n_components=200, tfidf__max_df=0.95 \n",
      "[CV]  clf__max_depth=10, clf__n_estimators=150, svd__n_components=200, tfidf__max_df=0.95, score=0.5732609023690961, total=  34.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  32 out of  32 | elapsed: 11.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=2, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.95, max_features=1000, min_df=3,\n",
       "        ngram_range=(1, 3), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "...n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'tfidf__max_df': (0.8, 0.95), 'svd__n_components': (100, 200), 'clf__n_estimators': (100, 150), 'clf__max_depth': (5, 10)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=5)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch.fit(df['ingredients_str'], df['cuisine'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tfidf': TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=0.8, max_features=1000, min_df=3,\n",
       "         ngram_range=(1, 3), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "         stop_words='english', strip_accents=None, sublinear_tf=False,\n",
       "         token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "         vocabulary=None),\n",
       " 'svd': TruncatedSVD(algorithm='randomized', n_components=100, n_iter=5,\n",
       "        random_state=None, tol=0.0),\n",
       " 'clf': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "             max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "             min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "             min_samples_leaf=1, min_samples_split=2,\n",
       "             min_weight_fraction_leaf=0.0, n_estimators=150, n_jobs=1,\n",
       "             oob_score=False, random_state=None, verbose=0,\n",
       "             warm_start=False)}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch.best_estimator_.named_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
